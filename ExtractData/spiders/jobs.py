# -*- coding: utf-8 -*-
# The program is designed to extract information from html file in local dirctory. 
# The tool is called scrapy which is used to scrape corresponding content based on tag.
# The output is a csv file contained vendor's name, comments, buyer's first and last letters,
# transaction amount, commented time and rating
# The total number of scraped html files is 629
# Other py files are default setting when generated by Scrapy, except settings.py. (The only modification is ROBOTSTXT_OBEY = False)
import scrapy
import csv
from os import listdir
from os.path import isfile, join
import re

# set up path, ready to read, html file name should not contain "#"
dir_path= "E:\yueyang\DarkWeb\Data\dream_market_data_seller_buyer"

onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]
add_files = ["file:///E:/yueyang/DarkWeb/Data/dream_market_data_seller_buyer/" + onlyfiles for onlyfiles in onlyfiles]
# Spider is the main class which define how a group of site will be scraped
class JobsSpider(scrapy.Spider):
    # define file name
    name = "jobs"
    start_urls = add_files

    # Process responses
    def parse(self, response):
        # Extract username
        username_tmp = response.xpath('//*[@class="pTable"]/tbody/tr/td/span/text()').extract_first().replace(' ','')
        # Extract number of transactions
        transactions = response.xpath('//*[@title="Successful transactions"]/text()').extract_first().replace('(','').replace(')','')
        # Extract vendor's average rating
        rating = response.xpath('//*[@class="userRating gold"]/text()').extract_first().replace('\xa0','')
        # Extract join date
        join_date = response.xpath('//*[@class="memberSince"]/span/text()').extract_first()
        # Extract last activie date
        last_active = re.sub("[\(\[].*?[\)\]]", "", response.xpath('//*[@class="profileNotes tabularDetails"]/div/span/text()').extract()[-1])
        # Extract trustful vote
        trust = response.xpath('//*[@class="trustDiv"]/div/text()').extract()[1].replace('\t','').replace(' ','')
        # Extract non-trustful vote
        untrust = response.xpath('//*[@class="trustDiv"]/div/text()').extract()[2].replace('\t','').replace(' ','') 
        # Output to csv file #
        with open('dream_market_seller.csv','a', encoding="utf-8",newline='') as f:
            fields = ['Vendor','Transactions','Rating','Join_date',"Last_active","Trust","Distrust"]
            writer = csv.DictWriter(f, fieldnames = fields)
            f.seek(0,2)
            if f.tell()==0:
                writer.writeheader()
            writer.writerow({'Vendor':username_tmp,
                             'Transactions':transactions,
                             'Rating':rating,
                             'Join_date':join_date,
                             'Last_active':last_active,
                             'Trust':trust,
                             'Distrust':untrust
                             })
        f.close()